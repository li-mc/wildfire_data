{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wildfire Size Class Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import sqlite3\n",
    "import julian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only pertinent features (this should make loading in data faster)\n",
    "con = sqlite3.connect(\"wildfire_data.sqlite\")\n",
    "query=\"\"\"\n",
    "SELECT \n",
    "FIRE_NAME,\n",
    "FIRE_SIZE_CLASS,\n",
    "STAT_CAUSE_DESCR, STAT_CAUSE_CODE,\n",
    "STATE, COUNTY,\n",
    "LONGITUDE, LATITUDE,\n",
    "DISCOVERY_DATE, \n",
    "DISCOVERY_TIME, \n",
    "CONT_DATE, \n",
    "CONT_TIME \n",
    "from Fires\n",
    "\"\"\"\n",
    "query=query.strip()\n",
    "df = pd.read_sql_query(query, con)\n",
    "con.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1880465, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIRE_NAME</th>\n",
       "      <th>FIRE_SIZE_CLASS</th>\n",
       "      <th>STAT_CAUSE_DESCR</th>\n",
       "      <th>STAT_CAUSE_CODE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>DISCOVERY_DATE</th>\n",
       "      <th>DISCOVERY_TIME</th>\n",
       "      <th>CONT_DATE</th>\n",
       "      <th>CONT_TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOUNTAIN</td>\n",
       "      <td>A</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>9.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>63</td>\n",
       "      <td>-121.005833</td>\n",
       "      <td>40.036944</td>\n",
       "      <td>2453403.5</td>\n",
       "      <td>1300</td>\n",
       "      <td>2453403.5</td>\n",
       "      <td>1730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PIGEON</td>\n",
       "      <td>A</td>\n",
       "      <td>Lightning</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>61</td>\n",
       "      <td>-120.404444</td>\n",
       "      <td>38.933056</td>\n",
       "      <td>2453137.5</td>\n",
       "      <td>0845</td>\n",
       "      <td>2453137.5</td>\n",
       "      <td>1530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SLACK</td>\n",
       "      <td>A</td>\n",
       "      <td>Debris Burning</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>17</td>\n",
       "      <td>-120.735556</td>\n",
       "      <td>38.984167</td>\n",
       "      <td>2453156.5</td>\n",
       "      <td>1921</td>\n",
       "      <td>2453156.5</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DEER</td>\n",
       "      <td>A</td>\n",
       "      <td>Lightning</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>3</td>\n",
       "      <td>-119.913333</td>\n",
       "      <td>38.559167</td>\n",
       "      <td>2453184.5</td>\n",
       "      <td>1600</td>\n",
       "      <td>2453189.5</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STEVENOT</td>\n",
       "      <td>A</td>\n",
       "      <td>Lightning</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>3</td>\n",
       "      <td>-119.933056</td>\n",
       "      <td>38.559167</td>\n",
       "      <td>2453184.5</td>\n",
       "      <td>1600</td>\n",
       "      <td>2453189.5</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FIRE_NAME FIRE_SIZE_CLASS STAT_CAUSE_DESCR  STAT_CAUSE_CODE STATE COUNTY  \\\n",
       "0  FOUNTAIN               A    Miscellaneous              9.0    CA     63   \n",
       "1    PIGEON               A        Lightning              1.0    CA     61   \n",
       "2     SLACK               A   Debris Burning              5.0    CA     17   \n",
       "3      DEER               A        Lightning              1.0    CA      3   \n",
       "4  STEVENOT               A        Lightning              1.0    CA      3   \n",
       "\n",
       "    LONGITUDE   LATITUDE  DISCOVERY_DATE DISCOVERY_TIME  CONT_DATE CONT_TIME  \n",
       "0 -121.005833  40.036944       2453403.5           1300  2453403.5      1730  \n",
       "1 -120.404444  38.933056       2453137.5           0845  2453137.5      1530  \n",
       "2 -120.735556  38.984167       2453156.5           1921  2453156.5      2024  \n",
       "3 -119.913333  38.559167       2453184.5           1600  2453189.5      1400  \n",
       "4 -119.933056  38.559167       2453184.5           1600  2453189.5      1200  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop rows with missing data\n",
    "Given our data is not sparse at all, we have the freedom to just drop all rows that are missing data we care about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(892007, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the following rows if they have missing data for the following features\n",
    "needed_cols = ['FIRE_SIZE_CLASS', 'DISCOVERY_DATE', 'DISCOVERY_TIME', 'CONT_DATE', 'CONT_TIME', 'STAT_CAUSE_CODE', 'STATE', 'LONGITUDE', 'LATITUDE']\n",
    "df = df.dropna(subset=needed_cols) # remove rows where both of these are missing\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new columns to work with\n",
    "\n",
    "Map fire size class to integers so they can be ordered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "di = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7}\n",
    "df['FIRE_SIZE_CLASS'] = df['FIRE_SIZE_CLASS'].map(di)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map states to indices to help handle categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = df.STATE.unique()\n",
    "ind = states.argsort(axis=0)\n",
    "state_di = {states[i]: i for i in ind}\n",
    "df['STATE_CODE']=df['STATE'].map(state_di)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the date/time columns to datetime objects. Originally they are in julian time. Also calculate the time to containment (time delta of containment date - discovery date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To make these dates and times easier to manage, let's convert them to datetime. We can add new columns DISCOVERY_DATETIME and CONTAINMENT_DATETIME.\n",
    "df['DISCOVERY_DATETIME'] = df['DISCOVERY_DATE'];\n",
    "df['CONT_DATETIME'] = df['CONT_DATE'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To populate those two rows, let's convert them into datetime.\n",
    "df['DISCOVERY_DATETIME'] = df['DISCOVERY_DATETIME'].apply(lambda x: julian.from_jd(x, fmt=\"jd\"))\n",
    "df['CONT_DATETIME'] = df['CONT_DATETIME'].apply(lambda x:julian.from_jd(x, fmt=\"jd\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2005-02-02 13:00:00\n",
       "1   2004-05-12 08:45:00\n",
       "2   2004-05-31 19:21:00\n",
       "3   2004-06-28 16:00:00\n",
       "4   2004-06-28 16:00:00\n",
       "Name: DISCOVERY_DATETIME, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's also add the time \n",
    "temp_df = pd.DataFrame();\n",
    "temp_df['dt'] = df['DISCOVERY_TIME'].apply(lambda x: dt.timedelta(hours=int(x[0:2]), minutes=int(x[2:5])))\n",
    "df['DISCOVERY_DATETIME'] = df['DISCOVERY_DATETIME'] + temp_df['dt']\n",
    "df['DISCOVERY_DATETIME'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2005-02-02 17:30:00\n",
       "1   2004-05-12 15:30:00\n",
       "2   2004-05-31 20:24:00\n",
       "3   2004-07-03 14:00:00\n",
       "4   2004-07-03 12:00:00\n",
       "Name: CONT_DATETIME, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Do the same thing for CONT_DATETIME\n",
    "temp_df = pd.DataFrame();\n",
    "temp_df['dt'] = df['CONT_TIME'].apply(lambda x: dt.timedelta(hours=int(x[0:2]), minutes=int(x[2:5])))\n",
    "df['CONT_DATETIME'] = df['CONT_DATETIME'] + temp_df['dt']\n",
    "df['CONT_DATETIME'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data_with_target.csv\")\n",
    "#Checkpoint to save the data with the above columns before reloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\somet\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (1,6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data_with_target.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{9.0: 'Miscellaneous',\n",
       " 1.0: 'Lightning',\n",
       " 5.0: 'Debris Burning',\n",
       " 4.0: 'Campfire',\n",
       " 2.0: 'Equipment Use',\n",
       " 7.0: 'Arson',\n",
       " 8.0: 'Children',\n",
       " 6.0: 'Railroad',\n",
       " 3.0: 'Smoking',\n",
       " 11.0: 'Powerline',\n",
       " 12.0: 'Structure',\n",
       " 10.0: 'Fireworks',\n",
       " 13.0: 'Missing/Undefined'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(df.STAT_CAUSE_CODE,df.STAT_CAUSE_DESCR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                     892007\n",
       "mean      1 days 06:44:52.524004\n",
       "std      13 days 19:33:02.720135\n",
       "min              0 days 00:00:00\n",
       "25%              0 days 00:30:00\n",
       "50%              0 days 01:28:00\n",
       "75%              0 days 04:45:00\n",
       "max           3653 days 01:30:00\n",
       "Name: TIME_TO_CONT, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CONT_DATETIME'] = df['CONT_DATETIME'].apply(lambda x: dt.datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "df['DISCOVERY_DATETIME'] = df['DISCOVERY_DATETIME'].apply(lambda x: dt.datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "df['TIME_TO_CONT'] = df['CONT_DATETIME'] - df['DISCOVERY_DATETIME']\n",
    "\n",
    "df['TIME_TO_CONT'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    892007.000000\n",
       "mean         30.728347\n",
       "std         331.551520\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           1.000000\n",
       "75%           5.000000\n",
       "max       87674.000000\n",
       "Name: HOURS_TO_CONT, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to hours for easier sorting\n",
    "df['HOURS_TO_CONT'] = df['TIME_TO_CONT'].apply(lambda x: round(float(x.total_seconds()/60/60)),2)\n",
    "df.HOURS_TO_CONT.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate the outliers in HOURS_TO_CONT \n",
    "\n",
    "75% is only 5 hours to cont, but max is abnormally high. \n",
    "Some dates seem to be incorrect (in record) -- month/day and time of day (h/m) are correct but wrong only in year.\n",
    "\n",
    "Be careful because some differences in year are okay (Dec/Jan fires).\n",
    "\n",
    "Since total dataset is 892007 instances, and of those, only 6000 are greater than 1000 hours to cont, these are definitely outliers and may need to be omitted from training for better accuracy/performance. We could also use a model that is insensitive to outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     5994.000000\n",
       "mean      2289.123624\n",
       "std       3257.553581\n",
       "min       1001.000000\n",
       "25%       1340.250000\n",
       "50%       1776.000000\n",
       "75%       2392.750000\n",
       "max      87674.000000\n",
       "Name: HOURS_TO_CONT, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.HOURS_TO_CONT > 1000].HOURS_TO_CONT.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.HOURS_TO_CONT > 8000) & (df.FIRE_SIZE_CLASS > 2)].sort_values(by='FIRE_SIZE_CLASS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\n",
    "    (df['DISCOVERY_DATETIME'].apply(lambda x: x.year) != df['CONT_DATETIME'].apply(lambda x: x.year))\n",
    "    &\n",
    "    (df['HOURS_TO_CONT'] > 200)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion on outliers:\n",
    "\n",
    "Probably best to drop ones with greater than 3000 hours. Looking at the fires that have > 1000 hours, most are within 2392. Safe to drop those with more as they are likely outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save intermediate copy\n",
    "df.to_pickle(\"data_with_target.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop cols not used in model\n",
    "drop_cols = ['FIRE_SIZE_CLASS', 'FIRE_NAME', 'STAT_CAUSE_DESCR', 'STATE', 'COUNTY', 'DISCOVERY_DATE',\n",
    "            'DISCOVERY_DATETIME', 'CONT_DATE', 'CONT_DATETIME', 'TIME_TO_CONT']\n",
    "X = df.drop(drop_cols, axis=1)\n",
    "y = df['FIRE_SIZE_CLASS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True,test_size=0.2, random_state=1)\n",
    "\n",
    "# create training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, shuffle=True, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = 10\n",
    "clf = DecisionTreeClassifier(max_depth=md).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree depth:  10\n",
      "# of leaves:  828\n",
      "Feature importance: \n",
      "\tUnnamed: 0: 0.207\n",
      "\tSTAT_CAUSE_CODE: 0.055\n",
      "\tLONGITUDE: 0.312\n",
      "\tLATITUDE: 0.073\n",
      "\tDISCOVERY_TIME: 0.004\n",
      "\tCONT_TIME: 0.01\n",
      "\tSTATE_CODE: 0.108\n",
      "\tHOURS_TO_CONT: 0.231\n",
      "Train score:  0.6598823250243365\n",
      "Test score:  0.6548188921648861\n"
     ]
    }
   ],
   "source": [
    "print(\"Tree depth: \", clf.get_depth())\n",
    "print(\"# of leaves: \", clf.get_n_leaves())\n",
    "print(\"Feature importance: \")\n",
    "for feature, value in dict(zip(X.columns.values, clf.feature_importances_)).items():\n",
    "    print(f\"\\t{feature:8}: {round(value,3)}\")\n",
    "print(\"Train score: \", clf.score(X_train, y_train))\n",
    "print(\"Test score: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove \"outliers\" and see if improvement\n",
    "X = df[df.HOURS_TO_CONT < 3000].drop(drop_cols, axis=1)\n",
    "y = df[df.HOURS_TO_CONT < 3000]['FIRE_SIZE_CLASS']\n",
    "# create testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True,test_size=0.2, random_state=1)\n",
    "\n",
    "# create training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, shuffle=True,test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree depth:  10\n",
      "# of leaves:  829\n",
      "Feature importance: \n",
      "\tUnnamed: 0: 0.209\n",
      "\tSTAT_CAUSE_CODE: 0.054\n",
      "\tLONGITUDE: 0.315\n",
      "\tLATITUDE: 0.074\n",
      "\tDISCOVERY_TIME: 0.004\n",
      "\tCONT_TIME: 0.01\n",
      "\tSTATE_CODE: 0.103\n",
      "\tHOURS_TO_CONT: 0.231\n",
      "Train score:  0.6615288220551379\n",
      "Test score:  0.6559945236532171\n"
     ]
    }
   ],
   "source": [
    "md = 10\n",
    "clf = DecisionTreeClassifier(max_depth=md).fit(X_train, y_train)\n",
    "print(\"Tree depth: \", clf.get_depth())\n",
    "print(\"# of leaves: \", clf.get_n_leaves())\n",
    "print(\"Feature importance: \")\n",
    "for feature, value in dict(zip(X.columns.values, clf.feature_importances_)).items():\n",
    "    print(f\"\\t{feature:8}: {round(value,3)}\")\n",
    "print(\"Train score: \", clf.score(X_train, y_train))\n",
    "print(\"Test score: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try undersampling to improve performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    386748\n",
       "1    380835\n",
       "3     92523\n",
       "4     14622\n",
       "5      8544\n",
       "6      5584\n",
       "7      3151\n",
       "Name: FIRE_SIZE_CLASS, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.FIRE_SIZE_CLASS.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skewed data, let's undersample 1 and 2\n",
    "sample2=df[df.FIRE_SIZE_CLASS == 2].sample(10000)\n",
    "sample1=df[df.FIRE_SIZE_CLASS == 1].sample(10000)\n",
    "sample3=df[df.FIRE_SIZE_CLASS == 3].sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154424, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIRE_NAME</th>\n",
       "      <th>FIRE_SIZE_CLASS</th>\n",
       "      <th>STAT_CAUSE_DESCR</th>\n",
       "      <th>STAT_CAUSE_CODE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>DISCOVERY_DATE</th>\n",
       "      <th>DISCOVERY_TIME</th>\n",
       "      <th>CONT_DATE</th>\n",
       "      <th>CONT_TIME</th>\n",
       "      <th>STATE_CODE</th>\n",
       "      <th>DISCOVERY_DATETIME</th>\n",
       "      <th>CONT_DATETIME</th>\n",
       "      <th>TIME_TO_CONT</th>\n",
       "      <th>HOURS_TO_CONT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>141589</th>\n",
       "      <td>POWERLINE</td>\n",
       "      <td>1</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>9.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>51</td>\n",
       "      <td>-117.038056</td>\n",
       "      <td>48.341667</td>\n",
       "      <td>2452134.5</td>\n",
       "      <td>1701</td>\n",
       "      <td>2452134.5</td>\n",
       "      <td>1910</td>\n",
       "      <td>6</td>\n",
       "      <td>2001-08-13 17:01:00</td>\n",
       "      <td>2001-08-13 19:10:00</td>\n",
       "      <td>02:09:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108195</th>\n",
       "      <td>FOSTER 3</td>\n",
       "      <td>1</td>\n",
       "      <td>Lightning</td>\n",
       "      <td>1.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-122.391667</td>\n",
       "      <td>43.031667</td>\n",
       "      <td>2451022.5</td>\n",
       "      <td>1900</td>\n",
       "      <td>2451022.5</td>\n",
       "      <td>2130</td>\n",
       "      <td>2</td>\n",
       "      <td>1998-07-28 19:00:00</td>\n",
       "      <td>1998-07-28 21:30:00</td>\n",
       "      <td>02:30:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783453</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Arson</td>\n",
       "      <td>7.0</td>\n",
       "      <td>SC</td>\n",
       "      <td>Dillon County</td>\n",
       "      <td>-79.320457</td>\n",
       "      <td>34.437176</td>\n",
       "      <td>2456571.5</td>\n",
       "      <td>1512</td>\n",
       "      <td>2456571.5</td>\n",
       "      <td>1556</td>\n",
       "      <td>17</td>\n",
       "      <td>2013-10-06 15:12:00</td>\n",
       "      <td>2013-10-06 15:56:00</td>\n",
       "      <td>00:44:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867354</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Debris Burning</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>Broome</td>\n",
       "      <td>-75.909600</td>\n",
       "      <td>42.146200</td>\n",
       "      <td>2457291.5</td>\n",
       "      <td>1454</td>\n",
       "      <td>2457291.5</td>\n",
       "      <td>1538</td>\n",
       "      <td>41</td>\n",
       "      <td>2015-09-26 14:54:00</td>\n",
       "      <td>2015-09-26 15:38:00</td>\n",
       "      <td>00:44:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619510</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Debris Burning</td>\n",
       "      <td>5.0</td>\n",
       "      <td>GA</td>\n",
       "      <td>Laurens</td>\n",
       "      <td>-83.025800</td>\n",
       "      <td>32.424000</td>\n",
       "      <td>2449055.5</td>\n",
       "      <td>1622</td>\n",
       "      <td>2449055.5</td>\n",
       "      <td>1705</td>\n",
       "      <td>30</td>\n",
       "      <td>1993-03-09 16:22:00</td>\n",
       "      <td>1993-03-09 17:05:00</td>\n",
       "      <td>00:43:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        FIRE_NAME  FIRE_SIZE_CLASS STAT_CAUSE_DESCR  STAT_CAUSE_CODE STATE  \\\n",
       "141589  POWERLINE                1    Miscellaneous              9.0    WA   \n",
       "108195   FOSTER 3                1        Lightning              1.0    OR   \n",
       "783453        NaN                1            Arson              7.0    SC   \n",
       "867354        NaN                1   Debris Burning              5.0    NY   \n",
       "619510        NaN                1   Debris Burning              5.0    GA   \n",
       "\n",
       "                      COUNTY   LONGITUDE   LATITUDE  DISCOVERY_DATE  \\\n",
       "141589                    51 -117.038056  48.341667       2452134.5   \n",
       "108195                   NaN -122.391667  43.031667       2451022.5   \n",
       "783453         Dillon County  -79.320457  34.437176       2456571.5   \n",
       "867354                Broome  -75.909600  42.146200       2457291.5   \n",
       "619510  Laurens               -83.025800  32.424000       2449055.5   \n",
       "\n",
       "        DISCOVERY_TIME  CONT_DATE  CONT_TIME  STATE_CODE  DISCOVERY_DATETIME  \\\n",
       "141589            1701  2452134.5       1910           6 2001-08-13 17:01:00   \n",
       "108195            1900  2451022.5       2130           2 1998-07-28 19:00:00   \n",
       "783453            1512  2456571.5       1556          17 2013-10-06 15:12:00   \n",
       "867354            1454  2457291.5       1538          41 2015-09-26 14:54:00   \n",
       "619510            1622  2449055.5       1705          30 1993-03-09 16:22:00   \n",
       "\n",
       "             CONT_DATETIME TIME_TO_CONT  HOURS_TO_CONT  \n",
       "141589 2001-08-13 19:10:00     02:09:00              2  \n",
       "108195 1998-07-28 21:30:00     02:30:00              2  \n",
       "783453 2013-10-06 15:56:00     00:44:00              1  \n",
       "867354 2015-09-26 15:38:00     00:44:00              1  \n",
       "619510 1993-03-09 17:05:00     00:43:00              1  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df= pd.concat([sample1, sample2, sample3,df[(df.FIRE_SIZE_CLASS != 1) & (df.FIRE_SIZE_CLASS != 2)]])\n",
    "sampled_df=sampled_df.drop('Unnamed: 0', axis=1)\n",
    "print(sampled_df.shape)\n",
    "sampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\somet\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n",
      "C:\\Users\\somet\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# remove \"outliers\" and see if improvement\n",
    "X = sampled_df[df.HOURS_TO_CONT < 3000].drop(drop_cols, axis=1)\n",
    "y = sampled_df[df.HOURS_TO_CONT < 3000]['FIRE_SIZE_CLASS']\n",
    "# create testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=1)\n",
    "\n",
    "# create training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, shuffle=True,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree depth:  10\n",
      "# of leaves:  787\n",
      "Feature importance: \n",
      "\tSTAT_CAUSE_CODE: 0.06\n",
      "\tLONGITUDE: 0.332\n",
      "\tLATITUDE: 0.1\n",
      "\tDISCOVERY_TIME: 0.029\n",
      "\tCONT_TIME: 0.033\n",
      "\tSTATE_CODE: 0.133\n",
      "\tHOURS_TO_CONT: 0.314\n",
      "Train score:  0.7099859505025398\n",
      "Test score:  0.6864868369861237\n"
     ]
    }
   ],
   "source": [
    "md = 10\n",
    "clf = DecisionTreeClassifier(max_depth=md).fit(X_train, y_train)\n",
    "print(\"Tree depth: \", clf.get_depth())\n",
    "print(\"# of leaves: \", clf.get_n_leaves())\n",
    "print(\"Feature importance: \")\n",
    "for feature, value in dict(zip(X.columns.values, clf.feature_importances_)).items():\n",
    "    print(f\"\\t{feature:8}: {round(value,3)}\")\n",
    "print(\"Train score: \", clf.score(X_train, y_train))\n",
    "print(\"Test score: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**: performance improved a lot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Even sampling across everything\n",
    "\n",
    "Sample so everything is max the lowest count of fire size classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22057, 17)\n"
     ]
    }
   ],
   "source": [
    "# skewed data, let's undersample 1 and 2\n",
    "sample1=df[df.FIRE_SIZE_CLASS == 1].sample(3151)\n",
    "sample2=df[df.FIRE_SIZE_CLASS == 2].sample(3151)\n",
    "sample3=df[df.FIRE_SIZE_CLASS == 3].sample(3151)\n",
    "sample4=df[df.FIRE_SIZE_CLASS == 4].sample(3151)\n",
    "sample5=df[df.FIRE_SIZE_CLASS == 5].sample(3151)\n",
    "sample6=df[df.FIRE_SIZE_CLASS == 6].sample(3151)\n",
    "sample7=df[df.FIRE_SIZE_CLASS==7]\n",
    "\n",
    "sampled_df= pd.concat([sample1, sample2, sample3, sample4, sample5, sample6, sample7])\n",
    "print(sampled_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\somet\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n",
      "C:\\Users\\somet\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# remove \"outliers\" and see if improvement\n",
    "X = sampled_df[df.HOURS_TO_CONT < 8000].drop(drop_cols, axis=1)\n",
    "y = sampled_df[df.HOURS_TO_CONT < 8000]['FIRE_SIZE_CLASS']\n",
    "# create testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=1)\n",
    "\n",
    "# create training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, shuffle=True,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree depth:  10\n",
      "# of leaves:  717\n",
      "Feature importance: \n",
      "\tSTAT_CAUSE_CODE: 0.046\n",
      "\tLONGITUDE: 0.216\n",
      "\tLATITUDE: 0.141\n",
      "\tDISCOVERY_TIME: 0.06\n",
      "\tCONT_TIME: 0.064\n",
      "\tHOURS_TO_CONT: 0.427\n",
      "\tSTATE_CODE: 0.046\n",
      "Train score:  0.5544554455445545\n",
      "Test score:  0.4180457946043981\n"
     ]
    }
   ],
   "source": [
    "md = 10\n",
    "clf = DecisionTreeClassifier(max_depth=md).fit(X_train, y_train)\n",
    "print(\"Tree depth: \", clf.get_depth())\n",
    "print(\"# of leaves: \", clf.get_n_leaves())\n",
    "print(\"Feature importance: \")\n",
    "for feature, value in dict(zip(X.columns.values, clf.feature_importances_)).items():\n",
    "    print(f\"\\t{feature:8}: {round(value,3)}\")\n",
    "print(\"Train score: \", clf.score(X_train, y_train))\n",
    "print(\"Test score: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**: performance degraded drastically by overrepresenting the rarer fire classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What next\n",
    "\n",
    "Select best max depth decision tree?\n",
    "\n",
    "Ensemble method Random Forest?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing DISCOVERY_TIME,  CONT_TIME columns as well (low feature importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skewed data, let's undersample 1 and 2\n",
    "sample2=df[df.FIRE_SIZE_CLASS == 2].sample(10000)\n",
    "sample1=df[df.FIRE_SIZE_CLASS == 1].sample(10000)\n",
    "sample3=df[df.FIRE_SIZE_CLASS == 3].sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154424, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIRE_NAME</th>\n",
       "      <th>FIRE_SIZE_CLASS</th>\n",
       "      <th>STAT_CAUSE_DESCR</th>\n",
       "      <th>STAT_CAUSE_CODE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>DISCOVERY_DATE</th>\n",
       "      <th>DISCOVERY_TIME</th>\n",
       "      <th>CONT_DATE</th>\n",
       "      <th>CONT_TIME</th>\n",
       "      <th>STATE_CODE</th>\n",
       "      <th>DISCOVERY_DATETIME</th>\n",
       "      <th>CONT_DATETIME</th>\n",
       "      <th>TIME_TO_CONT</th>\n",
       "      <th>HOURS_TO_CONT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171252</th>\n",
       "      <td>THIRSTY FIRE</td>\n",
       "      <td>1</td>\n",
       "      <td>Lightning</td>\n",
       "      <td>1.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>19</td>\n",
       "      <td>-122.080556</td>\n",
       "      <td>43.281389</td>\n",
       "      <td>2453230.5</td>\n",
       "      <td>1622</td>\n",
       "      <td>2453231.5</td>\n",
       "      <td>1910</td>\n",
       "      <td>2</td>\n",
       "      <td>2004-08-13 16:22:00</td>\n",
       "      <td>2004-08-14 19:10:00</td>\n",
       "      <td>1 days 02:48:00</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77138</th>\n",
       "      <td>HUFFER</td>\n",
       "      <td>1</td>\n",
       "      <td>Smoking</td>\n",
       "      <td>3.0</td>\n",
       "      <td>AZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-111.383333</td>\n",
       "      <td>34.486667</td>\n",
       "      <td>2449879.5</td>\n",
       "      <td>1630</td>\n",
       "      <td>2449879.5</td>\n",
       "      <td>1715</td>\n",
       "      <td>9</td>\n",
       "      <td>1995-06-11 16:30:00</td>\n",
       "      <td>1995-06-11 17:15:00</td>\n",
       "      <td>0 days 00:45:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748523</th>\n",
       "      <td>HALL</td>\n",
       "      <td>1</td>\n",
       "      <td>Lightning</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AZ</td>\n",
       "      <td>001</td>\n",
       "      <td>-109.511667</td>\n",
       "      <td>34.157222</td>\n",
       "      <td>2456487.5</td>\n",
       "      <td>808</td>\n",
       "      <td>2456488.5</td>\n",
       "      <td>1214</td>\n",
       "      <td>9</td>\n",
       "      <td>2013-07-14 08:08:00</td>\n",
       "      <td>2013-07-15 12:14:00</td>\n",
       "      <td>1 days 04:06:00</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202147</th>\n",
       "      <td>JACOBTALAS</td>\n",
       "      <td>1</td>\n",
       "      <td>Debris Burning</td>\n",
       "      <td>5.0</td>\n",
       "      <td>AZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-110.467400</td>\n",
       "      <td>35.783300</td>\n",
       "      <td>2451339.5</td>\n",
       "      <td>1830</td>\n",
       "      <td>2451339.5</td>\n",
       "      <td>2030</td>\n",
       "      <td>9</td>\n",
       "      <td>1999-06-10 18:30:00</td>\n",
       "      <td>1999-06-10 20:30:00</td>\n",
       "      <td>0 days 02:00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846757</th>\n",
       "      <td>TWENTY-ONE</td>\n",
       "      <td>1</td>\n",
       "      <td>Arson</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-106.689597</td>\n",
       "      <td>34.908500</td>\n",
       "      <td>2457157.5</td>\n",
       "      <td>1226</td>\n",
       "      <td>2457157.5</td>\n",
       "      <td>1303</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-15 12:26:00</td>\n",
       "      <td>2015-05-15 13:03:00</td>\n",
       "      <td>0 days 00:37:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           FIRE_NAME  FIRE_SIZE_CLASS STAT_CAUSE_DESCR  STAT_CAUSE_CODE STATE  \\\n",
       "171252  THIRSTY FIRE                1        Lightning              1.0    OR   \n",
       "77138         HUFFER                1          Smoking              3.0    AZ   \n",
       "748523          HALL                1        Lightning              1.0    AZ   \n",
       "202147    JACOBTALAS                1   Debris Burning              5.0    AZ   \n",
       "846757    TWENTY-ONE                1            Arson              7.0    NM   \n",
       "\n",
       "       COUNTY   LONGITUDE   LATITUDE  DISCOVERY_DATE  DISCOVERY_TIME  \\\n",
       "171252     19 -122.080556  43.281389       2453230.5            1622   \n",
       "77138     NaN -111.383333  34.486667       2449879.5            1630   \n",
       "748523    001 -109.511667  34.157222       2456487.5             808   \n",
       "202147    NaN -110.467400  35.783300       2451339.5            1830   \n",
       "846757    NaN -106.689597  34.908500       2457157.5            1226   \n",
       "\n",
       "        CONT_DATE  CONT_TIME  STATE_CODE  DISCOVERY_DATETIME  \\\n",
       "171252  2453231.5       1910           2 2004-08-13 16:22:00   \n",
       "77138   2449879.5       1715           9 1995-06-11 16:30:00   \n",
       "748523  2456488.5       1214           9 2013-07-14 08:08:00   \n",
       "202147  2451339.5       2030           9 1999-06-10 18:30:00   \n",
       "846757  2457157.5       1303           1 2015-05-15 12:26:00   \n",
       "\n",
       "             CONT_DATETIME    TIME_TO_CONT  HOURS_TO_CONT  \n",
       "171252 2004-08-14 19:10:00 1 days 02:48:00             27  \n",
       "77138  1995-06-11 17:15:00 0 days 00:45:00              1  \n",
       "748523 2013-07-15 12:14:00 1 days 04:06:00             28  \n",
       "202147 1999-06-10 20:30:00 0 days 02:00:00              2  \n",
       "846757 2015-05-15 13:03:00 0 days 00:37:00              1  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df= pd.concat([sample1, sample2, sample3,df[(df.FIRE_SIZE_CLASS != 1) & (df.FIRE_SIZE_CLASS != 2)]])\n",
    "sampled_df=sampled_df.drop('Unnamed: 0', axis=1)\n",
    "print(sampled_df.shape)\n",
    "sampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\somet\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\somet\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# remove \"outliers\" and see if improvement\n",
    "drop_cols2 = drop_cols + ['DISCOVERY_TIME', 'CONT_TIME']\n",
    "X = sampled_df[df.HOURS_TO_CONT < 3000].drop(drop_cols2, axis=1)\n",
    "y = sampled_df[df.HOURS_TO_CONT < 3000]['FIRE_SIZE_CLASS']\n",
    "# create testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=1)\n",
    "\n",
    "# create training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, shuffle=True,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree depth:  10\n",
      "# of leaves:  843\n",
      "Feature importance: \n",
      "\tSTAT_CAUSE_CODE: 0.059\n",
      "\tLONGITUDE: 0.348\n",
      "\tLATITUDE: 0.136\n",
      "\tSTATE_CODE: 0.137\n",
      "\tHOURS_TO_CONT: 0.32\n",
      "Train score:  0.7086535032260156\n",
      "Test score:  0.685870833873687\n"
     ]
    }
   ],
   "source": [
    "md = 10\n",
    "clf = DecisionTreeClassifier(max_depth=md).fit(X_train, y_train)\n",
    "print(\"Tree depth: \", clf.get_depth())\n",
    "print(\"# of leaves: \", clf.get_n_leaves())\n",
    "print(\"Feature importance: \")\n",
    "for feature, value in dict(zip(X.columns.values, clf.feature_importances_)).items():\n",
    "    print(f\"\\t{feature:8}: {round(value,3)}\")\n",
    "print(\"Train score: \", clf.score(X_train, y_train))\n",
    "print(\"Test score: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**: not that much improvement actually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
